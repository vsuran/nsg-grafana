input {
  file {
    path => "/home/logs/*.json"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => multiline {
      pattern => "^{"
      negate => "true"
      what => "previous"
      auto_flush_interval => 1
    }
  }
}

# input {
#   file {
#     path => "/home/logs/*.json"
#     start_position => "beginning"
#     sincedb_path => "/dev/null"
#     codec => json_lines
#   }
# }


filter {
  json {
    source => "message"
    target => "parsed_json"
    remove_field => ["message"]
  }


  split { field => "[parsed_json][properties][flows]" }
  split { field => "[parsed_json][properties][flows][flows]" }
  split { field => "[parsed_json][properties][flows][flows][flowTuples]" }

  mutate {
    split => { "[parsed_json][resourceId]" => "/" }
    add_field => { 
      "Subscription" => "%{[parsed_json][resourceId][2]}"
      "ResourceGroup" => "%{[parsed_json][resourceId][4]}"
      "NetworkSecurityGroup" => "%{[parsed_json][resourceId][8]}"
    }
    convert => {
      "Subscription" => "string"
      "ResourceGroup" => "string"
      "NetworkSecurityGroup" => "string"
    }
    split => { "[parsed_json][properties][flows][flows][flowTuples]" => "," }
    add_field => {
      "unixtimestamp" => "%{[parsed_json][properties][flows][flows][flowTuples][0]}"
      "srcIp" => "%{[parsed_json][properties][flows][flows][flowTuples][1]}"
      "destIp" => "%{[parsed_json][properties][flows][flows][flowTuples][2]}"
      "srcPort" => "%{[parsed_json][properties][flows][flows][flowTuples][3]}"
      "destPort" => "%{[parsed_json][properties][flows][flows][flowTuples][4]}"
      "protocol" => "%{[parsed_json][properties][flows][flows][flowTuples][5]}"
      "trafficflow" => "%{[parsed_json][properties][flows][flows][flowTuples][6]}"
      "traffic" => "%{[parsed_json][properties][flows][flows][flowTuples][7]}"
      "flowstate" => "%{[parsed_json][properties][flows][flows][flowTuples][8]}"
    }
    add_field => {
      "time" => "%{[parsed_json][time]}"
      "systemId" => "%{[parsed_json][systemId]}"
      "category" => "%{[parsed_json][category]}"
      "resourceId" => "%{[parsed_json][resourceId]}"
      "operationName" => "%{[parsed_json][operationName]}"
      "Version" => "%{[parsed_json][properties][Version]}"
      "rule" => "%{[parsed_json][properties][flows][rule]}"
      "mac" => "%{[parsed_json][properties][flows][flows][mac]}"
    }
    convert => {
      "unixtimestamp" => "integer"
      "srcPort" => "integer"
      "destPort" => "integer"
    }
    add_field => { "message" => "%{Message}" }
    remove_field => ["parsed_json"]
  }

  date {
    match => ["unixtimestamp", "UNIX"]
  }
}

output {
  stdout {
    codec => rubydebug
  }
  # file {
  #   path => "/home/nsg_flow_logs_output.json"
  #   codec => json_lines
  # }
  # elasticsearch {
  #   hosts => "http://elasticsearch:9200"
  #   index => "nsg-flow-logs"
  # }
}





input {
  file {
    # path => "/home/logs/advanced_nested.json"
    path => "/home/logs/sample-log.json"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => multiline {
      pattern => "^\[|^\{"
      negate => "true"
      what => "previous"
      auto_flush_interval => 1
    }
  }
}

filter {

  json {
    source => "message"
    target => "parsed_json"
    remove_field => ["message"]
  }

  split { field => "[parsed_json][properties][flows]" }
  split { field => "[parsed_json][properties][flows][flows]" }
  split { field => "[parsed_json][properties][flows][flows][flowTuples]" }

  mutate {
    split => { "[parsed_json][resourceId]" => "/" }
    add_field => { 
      "Subscription" => "%{[parsed_json][resourceId][2]}"
      "ResourceGroup" => "%{[parsed_json][resourceId][4]}"
      "NetworkSecurityGroup" => "%{[parsed_json][resourceId][8]}"
    }
    convert => {
      "Subscription" => "string"
      "ResourceGroup" => "string"
      "NetworkSecurityGroup" => "string"
    }




  }

  # if "_jsonparsefailure" in [tags] {
  #   drop { }
  # }


}


output {
  stdout {
    codec => rubydebug
  }
}