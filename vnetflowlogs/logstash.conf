input {
  file {

    path => "/usr/share/logstash/output_files/*.json"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => multiline {
      pattern => "^\[|^\{"
      negate => "true"
      what => "previous"
      auto_flush_interval => 1
    }
  }
}

filter {

  json {
    source => "message"
    target => "parsed_json"
    remove_field => ["message"]
  }
  split { field => "[parsed_json][flowRecords][flows]" }
  split { field => "[parsed_json][flowRecords][flows][aclID]" }
  split { field => "[parsed_json][flowRecords][flows][flowGroups]" }
  split { field => "[parsed_json][flowRecords][flows][flowGroups][flowTuples]" }

  mutate {
    split => { "[parsed_json][targetResourceID]" => "/" }
    add_field => { 
      "Subscription" => "%{[parsed_json][targetResourceID][2]}"
      "ResourceGroup" => "%{[parsed_json][targetResourceID][4]}"
      "VirtualNetworkName" => "%{[parsed_json][targetResourceID][8]}"
    }
    convert => {
      "Subscription" => "string"
      "ResourceGroup" => "string"
      "VirtualNetworkName" => "string"
    }
    split => { "[parsed_json][flowRecords][flows][aclID]" => "/" }
    add_field => {
        "NSGName" => "%{[parsed_json][flowRecords][flows][aclID][8]}"
    }
    split => { "[parsed_json][flowRecords][flows][flowGroups][rule]" => "," }
    add_field => {
        "NSGRule" => "%{[parsed_json][flowRecords][flows][flowGroups][rule]}"
    }
   split => { "[parsed_json][flowRecords][flows][flowGroups][flowTuples]" => "," }
    add_field => {
      "unixtimestamp" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][0]}"
      "srcIp" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][1]}"
      "destIp" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][2]}"
      "srcPort" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][3]}"
      "destPort" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][4]}"
      "protocol" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][5]}"
      "trafficflow" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][6]}"
      "flowstate" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][7]}"
      "encrypstat" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][8]}"
      "PackSent" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][9]}"
      "ByteSent" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][10]}"
      "PackRec" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][11]}"
      "ByteRec" => "%{[parsed_json][flowRecords][flows][flowGroups][flowTuples][12]}"
    }
    add_field => {
        "time" => "%{[parsed_json][time]}"
        "flowLogGuid" => "%{[parsed_json][flowLogGUID]}"
        "category" => "%{[parsed_json][category]}"
        "operationName" => "%{[parsed_json][operationName]}"
        "mac" => "%{[parsed_json][macAddress]}"
    }
    convert => {
      "unixtimestamp" => "integer"
      "srcPort" => "integer"
      "destPort" => "integer"
    }
    add_field => { "message" => "%{parsed_json}" }
    remove_field => ["parsed_json"]
  }
  date {
    match => ["unixtimestamp", "UNIX"]
  }
}
output {
  stdout {
    codec => rubydebug
  }
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "nsg-flow-logs"
  }
}


